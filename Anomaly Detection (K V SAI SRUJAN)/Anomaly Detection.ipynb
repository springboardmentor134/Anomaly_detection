{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\pc\\\\Desktop\\\\Crowd data for anomaly detection.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = df.describe()\n",
    "\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "summary, missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage = (df['Acc'].isnull().sum() / len(df)) * 100\n",
    "\n",
    "df['Acc'] = df['Acc'].fillna(df['Acc'].mean())\n",
    "\n",
    "missing_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of numerical columns\n",
    "numerical_columns = ['X', 'Y', 'Speed', 'Heading', 'AgentCount', 'Density', 'Acc', 'LevelOfCrowdness', 'Severity_level']\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "plt.figure(figsize=(20, 15))\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.histplot(df[column], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\pc\\\\Desktop\\\\Crowd data for anomaly detection.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['Speed'], kde=True)\n",
    "plt.title('Distribution of Speed')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='LevelOfCrowdness', y='Density', data=df)\n",
    "plt.title('Density by Level of Crowdness')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='X', y='Y', hue='label', data=df)\n",
    "plt.title('Spatial Distribution of Anomalies')\n",
    "plt.show()\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Speed_per_Density'] = df['Speed'] / df['Density']\n",
    "\n",
    "df[['Speed', 'Density', 'Speed_per_Density']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iqr_outliers(df):\n",
    "    outliers_dict = {}\n",
    "    for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "        outliers_dict[column] = {\n",
    "            'IQR': IQR,\n",
    "            'Lower Bound': lower_bound,\n",
    "            'Upper Bound': upper_bound,\n",
    "            'Outliers': outliers\n",
    "        }\n",
    "    \n",
    "    return outliers_dict\n",
    "\n",
    "outliers_info = calculate_iqr_outliers(df)\n",
    "\n",
    "for column, info in outliers_info.items():\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\" - IQR: {info['IQR']}\")\n",
    "    print(f\" - Lower Bound: {info['Lower Bound']}\")\n",
    "    print(f\" - Upper Bound: {info['Upper Bound']}\")\n",
    "    print(f\" - Number of Outliers: {len(info['Outliers'])}\")\n",
    "    print(f\" - Outliers: \\n{info['Outliers'].values}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "def calculate_zscore_outliers(df):\n",
    "    outliers_dict = {}\n",
    "    for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        df['Zscore'] = zscore(df[column].dropna())\n",
    "        outliers = df[(df['Zscore'] > 3) | (df['Zscore'] < -3)][column]\n",
    "        outliers_dict[column] = {\n",
    "            'Mean': df[column].mean(),\n",
    "            'Std Dev': df[column].std(),\n",
    "            'Outliers': outliers\n",
    "        }\n",
    "    \n",
    "    return outliers_dict\n",
    "\n",
    "\n",
    "outliers_info = calculate_zscore_outliers(df)\n",
    "\n",
    "\n",
    "for column, info in outliers_info.items():\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\" - Mean: {info['Mean']}\")\n",
    "    print(f\" - Standard Deviation: {info['Std Dev']}\")\n",
    "    print(f\" - Number of Outliers: {len(info['Outliers'])}\")\n",
    "    print(f\" - Outliers: \\n{info['Outliers'].values}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress the FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Load the data from the provided CSV file\n",
    "file_path = \"C:\\\\Users\\\\pc\\\\Desktop\\\\Crowd data for anomaly detection.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fill missing values in the 'Acc' column with the mean\n",
    "df['Acc'] = df['Acc'].fillna(df['Acc'].mean())\n",
    "\n",
    "# Create a dummy column 'true_labels' for demonstration purposes\n",
    "# In a real scenario, you would have actual true labels\n",
    "# Here, we assume that 1 indicates normal and -1 indicates anomalies\n",
    "np.random.seed(42)\n",
    "df['true_labels'] = np.random.choice([1, -1], size=len(df), p=[0.90, 0.10])\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(numeric_df.drop(columns=['true_labels']), \n",
    "                                                    numeric_df['true_labels'], \n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply Isolation Forest on the training set\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "iso_forest.fit(X_train)\n",
    "\n",
    "# Predict anomalies on the test set\n",
    "X_test['IsoForest_Anomaly'] = iso_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, X_test['IsoForest_Anomaly'])\n",
    "f1 = f1_score(y_test, X_test['IsoForest_Anomaly'], pos_label=-1)\n",
    "cm = confusion_matrix(y_test, X_test['IsoForest_Anomaly'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomaly'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Show the results\n",
    "iso_forest_counts = X_test['IsoForest_Anomaly'].value_counts()\n",
    "\n",
    "# Display counts\n",
    "print(\"Isolation Forest Anomaly Counts in Test Set:\")\n",
    "print(iso_forest_counts)\n",
    "\n",
    "# Display the first few rows of the anomaly detection results in the test set\n",
    "anomaly_results = X_test[['IsoForest_Anomaly']].head(10)\n",
    "print(\"\\nSample Results:\")\n",
    "print(anomaly_results)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Combine X_train and y_train for visualization\n",
    "X_train['true_labels'] = y_train\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='true_labels', palette={1: 'blue', -1: 'red'}, data=X_train)\n",
    "plt.title('Training Set')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize anomalies in the test set\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Heading', y='Density', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set (Heading vs Density)')\n",
    "plt.xlabel('Heading')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Density', y='LevelOfCrowdness', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set (Density vs LevelofCrowdness)')\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('LevelOfCrowdness')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='X', y='Speed', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set (X vs Speed)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Speed')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='X', y='Y', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set (X vs Y)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress the FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Load the data from the provided CSV file\n",
    "file_path = \"C:\\\\Users\\\\pc\\\\Desktop\\\\Crowd data for anomaly detection.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fill missing values in the 'Acc' column with the mean\n",
    "df['Acc'] = df['Acc'].fillna(df['Acc'].mean())\n",
    "\n",
    "# Create a dummy column 'true_labels' for demonstration purposes\n",
    "# In a real scenario, you would have actual true labels\n",
    "# Here, we assume that 1 indicates normal and -1 indicates anomalies\n",
    "np.random.seed(42)\n",
    "df['true_labels'] = np.random.choice([1, -1], size=len(df), p=[0.98, 0.02])\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(numeric_df.drop(columns=['true_labels']), \n",
    "                                                    numeric_df['true_labels'], \n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply Isolation Forest on the training set\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "iso_forest.fit(X_train)\n",
    "\n",
    "# Predict anomalies on the test set\n",
    "X_test['IsoForest_Anomaly'] = iso_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, X_test['IsoForest_Anomaly'])\n",
    "f1 = f1_score(y_test, X_test['IsoForest_Anomaly'], pos_label=-1)\n",
    "cm = confusion_matrix(y_test, X_test['IsoForest_Anomaly'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomaly'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Show the results\n",
    "iso_forest_counts = X_test['IsoForest_Anomaly'].value_counts()\n",
    "\n",
    "# Display counts\n",
    "print(\"Isolation Forest Anomaly Counts in Test Set:\")\n",
    "print(iso_forest_counts)\n",
    "\n",
    "# Display the first few rows of the anomaly detection results in the test set\n",
    "anomaly_results = X_test[['IsoForest_Anomaly']].head(10)\n",
    "print(\"\\nSample Results:\")\n",
    "print(anomaly_results)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Visualize anomalies in the test set\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X_train['true_labels'] = y_train\n",
    "# Combine X_train and y_train for visualization\n",
    "X_train['true_labels'] = y_train\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='true_labels', palette={1: 'blue', -1: 'red'}, data=X_train)\n",
    "plt.title('Training Set')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "X_test['true_labels'] = y_test\n",
    "# Visualize anomalies in the test set\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Heading', y='Density', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set (Heading vs Density)')\n",
    "plt.xlabel('Heading')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Density', y='LevelOfCrowdness', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set (Density vs LevelofCrowdness)')\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('LevelOfCrowdness')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='X', y='Speed', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set (X vs Speed)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Speed')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='X', y='Y', hue='IsoForest_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Isolation Forest Anomalies in Test Set (X vs Y)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"C:\\\\Users\\\\pc\\\\Desktop\\\\New folder (13)\\\\crowd_data_with_anomalies.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress the FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(numeric_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply K-Nearest Neighbors for anomaly detection on the training set\n",
    "knn = NearestNeighbors(n_neighbors=5)\n",
    "knn.fit(X_train)\n",
    "\n",
    "# Calculate distances and indices of the nearest neighbors for the test set\n",
    "distances, indices = knn.kneighbors(X_test)\n",
    "\n",
    "# Calculate the average distance to the k-nearest neighbors\n",
    "avg_distances = distances.mean(axis=1)\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = np.percentile(avg_distances, 95)  # Using the 95th percentile as the threshold\n",
    "\n",
    "# Predict anomalies\n",
    "X_test['KNN_Anomaly'] = avg_distances > threshold\n",
    "\n",
    "# Assuming we have some synthetic true labels for demonstration purposes\n",
    "# Here, we assume that 1 indicates normal and -1 indicates anomalies\n",
    "np.random.seed(42)\n",
    "y_test = np.random.choice([1, -1], size=len(X_test), p=[0.98, 0.02])\n",
    "\n",
    "# Map KNN_Anomaly boolean values to -1 for anomalies and 1 for normal\n",
    "X_test['KNN_Anomaly'] = X_test['KNN_Anomaly'].map({True: -1, False: 1})\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, X_test['KNN_Anomaly'])\n",
    "f1 = f1_score(y_test, X_test['KNN_Anomaly'], pos_label=-1)\n",
    "cm = confusion_matrix(y_test, X_test['KNN_Anomaly'])\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomaly'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='KNN_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('KNN Anomalies in Test Set')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the first few rows of the anomaly detection results in the test set\n",
    "anomaly_results = X_test[['KNN_Anomaly']].head(10)\n",
    "print(\"\\nSample Results:\")\n",
    "print(anomaly_results)\n",
    "\n",
    "# Show the counts of anomalies detected\n",
    "knn_counts = X_test['KNN_Anomaly'].value_counts()\n",
    "print(\"\\nKNN Anomaly Counts in Test Set:\")\n",
    "print(knn_counts)\n",
    "\n",
    "# Plot graph for x=Heading, y=Speed\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Heading', y='Speed', hue='KNN_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('KNN Anomalies in Test Set (Heading vs Speed)')\n",
    "plt.xlabel('Heading')\n",
    "plt.ylabel('Speed')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Create synthetic labels for the training set (for visualization purposes only)\n",
    "# Here, we assume that 1 indicates normal and -1 indicates anomalies\n",
    "np.random.seed(42)\n",
    "y_train_synthetic = np.random.choice([1, -1], size=len(X_train), p=[0.98, 0.02])\n",
    "X_train['KNN_Anomaly'] = y_train_synthetic\n",
    "\n",
    "# Visualize training data (Scatter Plot with Speed vs Density)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='KNN_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_train)\n",
    "plt.title('Training Set (Speed vs Density)')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize training data (Scatter Plot with Heading vs Speed)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Heading', y='Speed', hue='KNN_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_train)\n",
    "plt.title('Training Set (Heading vs Speed)')\n",
    "plt.xlabel('Heading')\n",
    "plt.ylabel('Speed')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress the FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(numeric_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply K-Nearest Neighbors for anomaly detection on the training set\n",
    "knn = NearestNeighbors(n_neighbors=5)\n",
    "knn.fit(X_train)\n",
    "\n",
    "# Calculate distances and indices of the nearest neighbors for the test set\n",
    "distances, indices = knn.kneighbors(X_test)\n",
    "\n",
    "# Calculate the average distance to the k-nearest neighbors\n",
    "avg_distances = distances.mean(axis=1)\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = np.percentile(avg_distances, 95)  # Using the 95th percentile as the threshold\n",
    "\n",
    "# Predict anomalies\n",
    "X_test['KNN_Anomaly'] = avg_distances > threshold\n",
    "\n",
    "# Assuming we have some synthetic true labels for demonstration purposes\n",
    "# Here, we assume that 1 indicates normal and -1 indicates anomalies\n",
    "np.random.seed(42)\n",
    "y_test = np.random.choice([1, -1], size=len(X_test), p=[0.98, 0.02])\n",
    "\n",
    "# Map KNN_Anomaly boolean values to -1 for anomalies and 1 for normal\n",
    "X_test['KNN_Anomaly'] = X_test['KNN_Anomaly'].map({True: -1, False: 1})\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, X_test['KNN_Anomaly'])\n",
    "f1 = f1_score(y_test, X_test['KNN_Anomaly'], pos_label=-1)\n",
    "cm = confusion_matrix(y_test, X_test['KNN_Anomaly'])\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomaly'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='KNN_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('KNN Anomalies in Test Set')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the first few rows of the anomaly detection results in the test set\n",
    "anomaly_results = X_test[['KNN_Anomaly']].head(10)\n",
    "print(\"\\nSample Results:\")\n",
    "print(anomaly_results)\n",
    "\n",
    "# Show the counts of anomalies detected\n",
    "knn_counts = X_test['KNN_Anomaly'].value_counts()\n",
    "print(\"\\nKNN Anomaly Counts in Test Set:\")\n",
    "print(knn_counts)\n",
    "\n",
    "# Plot graph for x=Heading, y=Speed\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Heading', y='Speed', hue='KNN_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('KNN Anomalies in Test Set (Heading vs Speed)')\n",
    "plt.xlabel('Heading')\n",
    "plt.ylabel('Speed')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress the FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test = train_test_split(numeric_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create dummy labels for demonstration purposes, as we don't have true labels\n",
    "np.random.seed(42)\n",
    "y_train = np.random.choice([1, -1], size=len(X_train), p=[0.98, 0.02])\n",
    "y_test = np.random.choice([1, -1], size=len(X_test), p=[0.98, 0.02])\n",
    "\n",
    "# Apply Decision Tree Classifier on the training set with limited depth\n",
    "decision_tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=-1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomaly'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Show the results\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(decision_tree, filled=True, feature_names=numeric_df.columns, class_names=['Normal', 'Anomaly'])\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "# Visualize anomalies in the test set\n",
    "X_test['DecisionTree_Anomaly'] = y_pred\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='DecisionTree_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Decision Tree Anomalies in Test Set')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Heading', y='Density', hue='DecisionTree_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Decision Tree Anomalies in Test Set (Heading vs Density)')\n",
    "plt.xlabel('Heading')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Density', y='LevelOfCrowdness', hue='DecisionTree_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Decision Tree Anomalies in Test Set (Density vs LevelOfCrowdness)')\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('LevelOfCrowdness')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='X', y='Speed', hue='DecisionTree_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Decision Tree Anomalies in Test Set (X vs Speed)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Speed')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='X', y='Y', hue='DecisionTree_Anomaly', palette={1: 'blue', -1: 'red'}, data=X_test)\n",
    "plt.title('Decision Tree Anomalies in Test Set (X vs Y)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress the FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Load the data from the provided CSV file\n",
    "file_path = \"C:\\\\Users\\\\pc\\\\Desktop\\\\Crowd data for anomaly detection.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fill missing values in the 'Acc' column with the mean\n",
    "df['Acc'] = df['Acc'].fillna(df['Acc'].mean())\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(scaled_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the first few rows of X_train\n",
    "print(\"\\nFirst few rows of X_train:\")\n",
    "print(X_train.head())\n",
    "\n",
    "# Add dummy labels to X_train for visualization\n",
    "np.random.seed(42)\n",
    "X_train['dummy_labels'] = np.random.choice([0, 1], size=len(X_train), p=[0.98, 0.02])\n",
    "\n",
    "# Define a custom scoring function\n",
    "def custom_scoring(estimator, X):\n",
    "    # Predict using the estimator\n",
    "    predictions = estimator.predict(X)\n",
    "    # We assume anomalies are -1 and normal points are 1\n",
    "    # Flip the predictions to match dummy true labels (1 for normal, 0 for anomaly)\n",
    "    predictions = np.where(predictions == 1, 0, 1)\n",
    "    # Generate dummy true labels\n",
    "    y_dummy = np.random.choice([0, 1], size=len(predictions), p=[0.98, 0.02])\n",
    "    # Calculate and return the F1 score\n",
    "    return f1_score(y_dummy, predictions)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV with custom scoring\n",
    "param_grid = {\n",
    "    'nu': [0.01, 0.05, 0.1],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01, 1]\n",
    "}\n",
    "grid_search = GridSearchCV(OneClassSVM(kernel=\"rbf\"), param_grid, cv=5, scoring=make_scorer(custom_scoring))\n",
    "grid_search.fit(X_train.drop(columns=['dummy_labels']))\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_svm = grid_search.best_estimator_\n",
    "best_svm.fit(X_train.drop(columns=['dummy_labels']))\n",
    "\n",
    "# Predict anomalies on the test set\n",
    "X_test['SVM_Anomaly'] = best_svm.predict(X_test)\n",
    "\n",
    "# Map the prediction results (-1 for anomaly, 1 for normal)\n",
    "X_test['SVM_Anomaly'] = X_test['SVM_Anomaly'].map({1: 0, -1: 1})\n",
    "\n",
    "# Display the first few rows of the anomaly detection results in the test set\n",
    "anomaly_results = X_test[['SVM_Anomaly']].head(10)\n",
    "print(\"\\nSample Results:\")\n",
    "print(anomaly_results)\n",
    "\n",
    "# Show the counts of anomalies detected\n",
    "svm_counts = X_test['SVM_Anomaly'].value_counts()\n",
    "print(\"\\nSVM Anomaly Counts in Test Set:\")\n",
    "print(svm_counts)\n",
    "\n",
    "# Visualize the training data with dummy labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='dummy_labels', palette={0: 'blue', 1: 'red'}, data=X_train)\n",
    "plt.title('Training Set (Speed vs Density)')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize anomalies in the test set\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='SVM_Anomaly', palette={0: 'blue', 1: 'red'}, data=X_test)\n",
    "plt.title('SVM Anomalies in Test Set (Speed vs Density)')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot graph for x=Heading, y=Speed\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Heading', y='Speed', hue='SVM_Anomaly', palette={0: 'blue', 1: 'red'}, data=X_test)\n",
    "plt.title('SVM Anomalies in Test Set (Heading vs Speed)')\n",
    "plt.xlabel('Heading')\n",
    "plt.ylabel('Speed')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot graph for x=Density, y=LevelOfCrowdness\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Density', y='LevelOfCrowdness', hue='SVM_Anomaly', palette={0: 'blue', 1: 'red'}, data=X_test)\n",
    "plt.title('SVM Anomalies in Test Set (Density vs LevelOfCrowdness)')\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('LevelOfCrowdness')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot graph for x=X, y=Speed\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='X', y='Speed', hue='SVM_Anomaly', palette={0: 'blue', 1: 'red'}, data=X_test)\n",
    "plt.title('SVM Anomalies in Test Set (X vs Speed)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Speed')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot graph for x=X, y=Y\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='X', y='Y', hue='SVM_Anomaly', palette={0: 'blue', 1: 'red'}, data=X_test)\n",
    "plt.title('SVM Anomalies in Test Set (X vs Y)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model using dummy true labels\n",
    "np.random.seed(42)\n",
    "y_test_dummy = np.random.choice([0, 1], size=len(X_test), p=[0.98, 0.02])\n",
    "\n",
    "accuracy = accuracy_score(y_test_dummy, X_test['SVM_Anomaly'])\n",
    "f1 = f1_score(y_test_dummy, X_test['SVM_Anomaly'])\n",
    "cm = confusion_matrix(y_test_dummy, X_test['SVM_Anomaly'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomaly'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress the FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Fill missing values in the 'Acc' column with the mean\n",
    "if 'Acc' in df.columns:\n",
    "    df['Acc'] = df['Acc'].fillna(df['Acc'].mean())\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(scaled_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# For visualization purposes, assume 'Speed' and 'Density' columns exist\n",
    "# and we want to visualize using these columns\n",
    "if 'Speed' not in X_train.columns or 'Density' not in X_train.columns:\n",
    "    raise ValueError(\"Columns 'Speed' and 'Density' must exist in the dataset for plotting.\")\n",
    "\n",
    "# Train the OneClassSVM on the training data\n",
    "svm = OneClassSVM(kernel='rbf', gamma='auto', nu=0.05)\n",
    "svm.fit(X_train)\n",
    "\n",
    "# Predict anomalies on the test set\n",
    "X_test['SVM_Anomaly'] = svm.predict(X_test)\n",
    "\n",
    "# Map the prediction results (-1 for anomaly, 1 for normal)\n",
    "X_test['SVM_Anomaly'] = X_test['SVM_Anomaly'].map({1: 0, -1: 1})\n",
    "\n",
    "# Display the first few rows of the anomaly detection results in the test set\n",
    "anomaly_results = X_test[['SVM_Anomaly']].head(10)\n",
    "print(\"\\nSample Results:\")\n",
    "print(anomaly_results)\n",
    "\n",
    "# Show the counts of anomalies detected\n",
    "svm_counts = X_test['SVM_Anomaly'].value_counts()\n",
    "print(\"\\nSVM Anomaly Counts in Test Set:\")\n",
    "print(svm_counts)\n",
    "\n",
    "# Visualize the training data with assumed normal points (dummy labels)\n",
    "np.random.seed(42)\n",
    "X_train['dummy_labels'] = np.random.choice([0, 1], size=len(X_train), p=[0.98, 0.02])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='dummy_labels', palette={0: 'blue', 1: 'red'}, data=X_train)\n",
    "plt.title('Training Set (Speed vs Density)')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize anomalies in the test set\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Speed', y='Density', hue='SVM_Anomaly', palette={0: 'blue', 1: 'red'}, data=X_test)\n",
    "plt.title('SVM Anomalies in Test Set (Speed vs Density)')\n",
    "plt.xlabel('Speed')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model using dummy true labels\n",
    "np.random.seed(42)\n",
    "y_test_dummy = np.random.choice([0, 1], size=len(X_test), p=[0.98, 0.02])\n",
    "\n",
    "accuracy = accuracy_score(y_test_dummy, X_test['SVM_Anomaly'])\n",
    "f1 = f1_score(y_test_dummy, X_test['SVM_Anomaly'])\n",
    "cm = confusion_matrix(y_test_dummy, X_test['SVM_Anomaly'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomaly'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
