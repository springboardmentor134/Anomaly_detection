{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ce0wbCqNz4K",
        "outputId": "9c1fa4f6-4bbf-49f6-df8e-6449b05a896e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Collecting hickle\n",
            "  Downloading hickle-5.0.3-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from hickle) (3.9.0)\n",
            "Requirement already satisfied: numpy!=1.20,>=1.8 in /usr/local/lib/python3.10/dist-packages (from hickle) (1.25.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n",
            "Installing collected packages: hickle, opendatasets\n",
            "Successfully installed hickle-5.0.3 opendatasets-0.1.22\n",
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: ayushaiml\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/karthiknm1/ucsd-anomaly-detection-dataset\n",
            "Downloading ucsd-anomaly-detection-dataset.zip to ./ucsd-anomaly-detection-dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 702M/702M [00:11<00:00, 62.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install opendatasets hickle\n",
        "\n",
        "import opendatasets as od\n",
        "import os\n",
        "\n",
        "# Download dataset\n",
        "od.download(\"https://www.kaggle.com/datasets/karthiknm1/ucsd-anomaly-detection-dataset\")\n",
        "\n",
        "# Check if the data is downloaded successfully\n",
        "if os.path.exists(\"/content/ucsd-anomaly-detection-dataset\"):\n",
        "    print(\"Dataset downloaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to download dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_YImno4N8VQ"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T97OathoORca"
      },
      "outputs": [],
      "source": [
        "# Load a subset of images from a directory\n",
        "def load_images_from_directory(directory, target_size=(128, 128), grayscale=False, load_fraction=0.3):\n",
        "    images = []\n",
        "    labels = []\n",
        "    total_files = []\n",
        "\n",
        "    # Gather all files from the directory\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif', 'tif', 'tiff')):\n",
        "                total_files.append(os.path.join(root, file))\n",
        "\n",
        "    # Calculate the number of files to load\n",
        "    num_files_to_load = int(len(total_files) * load_fraction)\n",
        "    files_to_load = np.random.choice(total_files, num_files_to_load, replace=False)\n",
        "\n",
        "    # Load the selected files\n",
        "    for img_path in files_to_load:\n",
        "        try:\n",
        "            if grayscale:\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if img is None:\n",
        "                    print(f\"Error loading image {img_path}: Image is None\")\n",
        "                    continue\n",
        "                img = cv2.resize(img, target_size)\n",
        "                img = np.expand_dims(img, axis=-1)  # Add a channel dimension\n",
        "            else:\n",
        "                img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "                img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            img = img / 255.0\n",
        "            images.append(img)\n",
        "            label = 0 if 'Train' in root else 1  # Simple logic to assign labels\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4teb3zFaOWdH"
      },
      "outputs": [],
      "source": [
        "# Define directories\n",
        "normal_dir = \"/content/ucsd-anomaly-detection-dataset/UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train\"\n",
        "anomaly_dir = \"/content/ucsd-anomaly-detection-dataset/UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-8AKU5KOqNK",
        "outputId": "8875535d-b9a8-481d-9f23-5f0675239096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of normal images loaded: 2040\n",
            "Normal Images shape: (2040, 128, 128, 3)\n",
            "Normal Labels shape: (2040,)\n",
            "Number of anomaly images loaded: 2760\n",
            "Anomaly Images shape: (2760, 128, 128, 3)\n",
            "Anomaly Labels shape: (2760,)\n"
          ]
        }
      ],
      "source": [
        "# Load images (30% of the total data)\n",
        "normal_images, normal_labels = load_images_from_directory(normal_dir, target_size=(128, 128), load_fraction=0.3)\n",
        "anomaly_images, anomaly_labels = load_images_from_directory(anomaly_dir, target_size=(128, 128), load_fraction=0.3)\n",
        "\n",
        "\n",
        "print(f\"Number of normal images loaded: {len(normal_images)}\")\n",
        "print(f\"Normal Images shape: {normal_images.shape}\")\n",
        "print(f\"Normal Labels shape: {normal_labels.shape}\")\n",
        "print(f\"Number of anomaly images loaded: {len(anomaly_images)}\")\n",
        "print(f\"Anomaly Images shape: {anomaly_images.shape}\")\n",
        "print(f\"Anomaly Labels shape: {anomaly_labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku200AJ7OxZa"
      },
      "outputs": [],
      "source": [
        "# Combine normal and anomaly images\n",
        "all_images = np.concatenate([normal_images, anomaly_images], axis=0)\n",
        "all_labels = np.concatenate([normal_labels, anomaly_labels], axis=0)\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(all_images, all_labels, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM7XYkxDSCWF",
        "outputId": "b952e4b0-75d7-403b-da81-d415c70c2e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 74s 806ms/step - loss: 0.6434 - accuracy: 0.6042 - val_loss: 0.5381 - val_accuracy: 0.7677\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 77s 849ms/step - loss: 0.4969 - accuracy: 0.7542 - val_loss: 0.4372 - val_accuracy: 0.7792\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 80s 887ms/step - loss: 0.4107 - accuracy: 0.8069 - val_loss: 0.3564 - val_accuracy: 0.8448\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 71s 787ms/step - loss: 0.3260 - accuracy: 0.8625 - val_loss: 0.2829 - val_accuracy: 0.8896\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 76s 853ms/step - loss: 0.2405 - accuracy: 0.9042 - val_loss: 0.2233 - val_accuracy: 0.9125\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 75s 840ms/step - loss: 0.1759 - accuracy: 0.9316 - val_loss: 0.2436 - val_accuracy: 0.9031\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 77s 852ms/step - loss: 0.1366 - accuracy: 0.9524 - val_loss: 0.1571 - val_accuracy: 0.9458\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 76s 852ms/step - loss: 0.0889 - accuracy: 0.9701 - val_loss: 0.1686 - val_accuracy: 0.9406\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 74s 822ms/step - loss: 0.0606 - accuracy: 0.9819 - val_loss: 0.1436 - val_accuracy: 0.9521\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 76s 846ms/step - loss: 0.0468 - accuracy: 0.9858 - val_loss: 0.1563 - val_accuracy: 0.9542\n"
          ]
        }
      ],
      "source": [
        "# Define Neural Network Models\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "input_shape = (128, 128, 3)\n",
        "cnn_model = create_cnn_model(input_shape)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "cnn_history = cnn_model.fit(X_train, y_train,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            epochs=10, callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxfcSBseXfI5",
        "outputId": "3dae2eae-b013-416a-edcb-f228802beac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 24s 258ms/step - loss: 2.8334 - accuracy: 0.5469 - val_loss: 0.6460 - val_accuracy: 0.5885\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 25s 271ms/step - loss: 0.6927 - accuracy: 0.5795 - val_loss: 0.6119 - val_accuracy: 0.5885\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.6330 - accuracy: 0.5795 - val_loss: 0.6035 - val_accuracy: 0.5885\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 25s 280ms/step - loss: 0.6472 - accuracy: 0.5795 - val_loss: 0.6017 - val_accuracy: 0.5885\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.6106 - accuracy: 0.5795 - val_loss: 0.6010 - val_accuracy: 0.5885\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.7646 - accuracy: 0.5795 - val_loss: 0.6013 - val_accuracy: 0.5885\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 22s 244ms/step - loss: 0.6093 - accuracy: 0.5795 - val_loss: 0.6009 - val_accuracy: 0.5885\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 23s 261ms/step - loss: 0.6084 - accuracy: 0.5795 - val_loss: 0.6007 - val_accuracy: 0.5885\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 22s 241ms/step - loss: 0.6497 - accuracy: 0.5795 - val_loss: 0.6008 - val_accuracy: 0.5885\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.6778 - accuracy: 0.5795 - val_loss: 0.6008 - val_accuracy: 0.5885\n"
          ]
        }
      ],
      "source": [
        "# Define ANN Model\n",
        "def create_ann_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "ann_model = create_ann_model(input_shape)\n",
        "\n",
        "ann_history = ann_model.fit(X_train, y_train,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            epochs=10, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFEhobinXiej",
        "outputId": "0468c944-34cc-4221-a1c4-222e7556ffaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 53s 562ms/step - loss: 5.8057 - accuracy: 0.5219 - val_loss: 0.6717 - val_accuracy: 0.5885\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 49s 546ms/step - loss: 0.6805 - accuracy: 0.5771 - val_loss: 0.6377 - val_accuracy: 0.5885\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 50s 561ms/step - loss: 0.6593 - accuracy: 0.5764 - val_loss: 0.6149 - val_accuracy: 0.5885\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 50s 556ms/step - loss: 0.6177 - accuracy: 0.5785 - val_loss: 0.6045 - val_accuracy: 0.5885\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 49s 540ms/step - loss: 0.6177 - accuracy: 0.5795 - val_loss: 0.6023 - val_accuracy: 0.5885\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 51s 567ms/step - loss: 0.6096 - accuracy: 0.5795 - val_loss: 0.6012 - val_accuracy: 0.5885\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 49s 542ms/step - loss: 0.6302 - accuracy: 0.5795 - val_loss: 0.6013 - val_accuracy: 0.5885\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 51s 565ms/step - loss: 0.6090 - accuracy: 0.5795 - val_loss: 0.6008 - val_accuracy: 0.5885\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 57s 631ms/step - loss: 0.6089 - accuracy: 0.5792 - val_loss: 0.6007 - val_accuracy: 0.5885\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 51s 568ms/step - loss: 0.6085 - accuracy: 0.5795 - val_loss: 0.6006 - val_accuracy: 0.5885\n"
          ]
        }
      ],
      "source": [
        "# Define MLP Model\n",
        "def create_mlp_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "mlp_model = create_mlp_model(input_shape)\n",
        "\n",
        "mlp_history = mlp_model.fit(X_train, y_train,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            epochs=10, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS8vF5YeXpRm",
        "outputId": "cd18a036-96bc-4e05-8a96-410837d9929b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 9s 289ms/step - loss: 0.2161 - accuracy: 0.9281\n",
            "CNN Validation Accuracy: 0.9281250238418579\n",
            "30/30 [==============================] - 6s 202ms/step - loss: 0.2345 - accuracy: 0.9146\n",
            "CNN Test Accuracy: 0.9145833253860474\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.6008 - accuracy: 0.5885\n",
            "ANN Validation Accuracy: 0.5885416865348816\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.6188 - accuracy: 0.5479\n",
            "ANN Test Accuracy: 0.5479166507720947\n",
            "30/30 [==============================] - 3s 93ms/step - loss: 0.6006 - accuracy: 0.5885\n",
            "MLP Validation Accuracy: 0.5885416865348816\n",
            "30/30 [==============================] - 2s 68ms/step - loss: 0.6185 - accuracy: 0.5479\n",
            "MLP Test Accuracy: 0.5479166507720947\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Models\n",
        "cnn_val_loss, cnn_val_acc = cnn_model.evaluate(X_val, y_val)\n",
        "print(\"CNN Validation Accuracy:\", cnn_val_acc)\n",
        "\n",
        "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(X_test, y_test)\n",
        "print(\"CNN Test Accuracy:\", cnn_test_acc)\n",
        "\n",
        "ann_val_loss, ann_val_acc = ann_model.evaluate(X_val, y_val)\n",
        "print(\"ANN Validation Accuracy:\", ann_val_acc)\n",
        "\n",
        "ann_test_loss, ann_test_acc = ann_model.evaluate(X_test, y_test)\n",
        "print(\"ANN Test Accuracy:\", ann_test_acc)\n",
        "\n",
        "mlp_val_loss, mlp_val_acc = mlp_model.evaluate(X_val, y_val)\n",
        "print(\"MLP Validation Accuracy:\", mlp_val_acc)\n",
        "\n",
        "mlp_test_loss, mlp_test_acc = mlp_model.evaluate(X_test, y_test)\n",
        "print(\"MLP Test Accuracy:\", mlp_test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZwkKTfLXuD-",
        "outputId": "3504ea57-cef1-471e-e1bd-09cf02fea3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Isolation Forest Accuracy: 0.45208333333333334\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.89      0.60       434\n",
            "           1       0.50      0.09      0.15       526\n",
            "\n",
            "    accuracy                           0.45       960\n",
            "   macro avg       0.47      0.49      0.37       960\n",
            "weighted avg       0.48      0.45      0.35       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Isolation Forest\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "iso_forest = IsolationForest(contamination=0.1)\n",
        "iso_forest.fit(X_train.reshape((X_train.shape[0], -1)))\n",
        "y_pred_iso = iso_forest.predict(X_test.reshape((X_test.shape[0], -1)))\n",
        "y_pred_iso = [0 if x == 1 else 1 for x in y_pred_iso]  # Convert to binary labels\n",
        "\n",
        "print(\"Isolation Forest Accuracy:\", accuracy_score(y_test, y_pred_iso))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_iso))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISouxbmAYDHZ",
        "outputId": "98178868-cd59-4c19-92b7-0bf11dd2f4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Local Outlier Factor Accuracy: 0.5020833333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.94      0.63       434\n",
            "           1       0.75      0.14      0.23       526\n",
            "\n",
            "    accuracy                           0.50       960\n",
            "   macro avg       0.61      0.54      0.43       960\n",
            "weighted avg       0.63      0.50      0.41       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Local Outlier Factor (LOF)\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Flatten images for LOF\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
        "y_pred_lof = lof.fit_predict(X_test_flat)\n",
        "y_pred_lof = [0 if x == 1 else 1 for x in y_pred_lof]\n",
        "\n",
        "print(\"Local Outlier Factor Accuracy:\", accuracy_score(y_test, y_pred_lof))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lof))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmcmIf7VYDqU",
        "outputId": "d2e1af06-eee7-4c2d-fff9-0f793433b522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-Class SVM Accuracy: 0.4395833333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.93      0.60       434\n",
            "           1       0.38      0.03      0.06       526\n",
            "\n",
            "    accuracy                           0.44       960\n",
            "   macro avg       0.41      0.48      0.33       960\n",
            "weighted avg       0.41      0.44      0.31       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# One-Class SVM\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "one_class_svm = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.03)\n",
        "one_class_svm.fit(X_train_flat)\n",
        "y_pred_svm = one_class_svm.predict(X_test_flat)\n",
        "y_pred_svm = [0 if x == 1 else 1 for x in y_pred_svm]\n",
        "\n",
        "print(\"One-Class SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S4fikrst6Ld",
        "outputId": "b5bf7f28-78d6-4deb-94cf-d59d5242d947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 87s 948ms/step - loss: 0.5790 - val_loss: 0.5083\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 83s 921ms/step - loss: 0.5119 - val_loss: 0.5055\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 85s 948ms/step - loss: 0.5102 - val_loss: 0.5042\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 85s 948ms/step - loss: 0.5092 - val_loss: 0.5034\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 84s 939ms/step - loss: 0.5085 - val_loss: 0.5030\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 89s 988ms/step - loss: 0.5081 - val_loss: 0.5027\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 86s 953ms/step - loss: 0.5079 - val_loss: 0.5024\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 87s 971ms/step - loss: 0.5076 - val_loss: 0.5022\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 86s 962ms/step - loss: 0.5075 - val_loss: 0.5021\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 85s 952ms/step - loss: 0.5073 - val_loss: 0.5019\n",
            "30/30 [==============================] - 9s 289ms/step\n",
            "Number of anomalies detected: 48\n",
            "Accuracy: 0.42291666666666666\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define Autoencoder Model\n",
        "def create_autoencoder(input_shape):\n",
        "    input_img = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    # Change the number of output channels to 3 to match input\n",
        "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "    return autoencoder\n",
        "\n",
        "# Example usage\n",
        "input_shape = (128, 128, 3)  # Update with your image dimensions\n",
        "autoencoder = create_autoencoder(input_shape)\n",
        "\n",
        "# Train the autoencoder on normal images\n",
        "autoencoder.fit(X_train, X_train, epochs=10, batch_size=32, validation_data=(X_val, X_val))\n",
        "\n",
        "# Use the autoencoder to predict and compute reconstruction errors\n",
        "reconstructed_images = autoencoder.predict(X_test)\n",
        "reconstruction_errors = np.mean(np.abs(X_test - reconstructed_images), axis=(1, 2, 3))\n",
        "\n",
        "# Use reconstruction errors for anomaly detection\n",
        "threshold = np.percentile(reconstruction_errors, 95)  # Example threshold\n",
        "anomalies = reconstruction_errors > threshold\n",
        "\n",
        "# Assuming y_test contains true labels (0 for normal, 1 for anomaly)\n",
        "y_pred = anomalies.astype(int) # Convert boolean anomalies to 0 and 1\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Number of anomalies detected:\", np.sum(anomalies))\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sowkMPMtbrq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}